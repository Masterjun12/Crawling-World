{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stolenforpractice.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOsI4zFnQNF65MCj4fGyAhn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oylim98/Crawling-World/blob/master/stolenforpractice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8ALlE55GOgw"
      },
      "source": [
        "네이버 증권 종목 순위 크롤링 (https://kjk92.tistory.com/63 크롤링 라이브러리 설명)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFf1dSUoEukh"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://finance.naver.com/sise/lastsearch2.nhn'\n",
        "dfs = pd.read_html(url,match='순위',encoding='euc-kr')\n",
        "\n",
        "print(dfs[0][['순위', '종목명','현재가']].dropna(how=\"all\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9eCHqn4GYd0"
      },
      "source": [
        "멜론 차트 크롤링 구글드라이브 활용 (https://velog.io/@rimi/Python-%EB%8B%A4%EB%93%A4-%ED%95%98%EB%8A%94-%ED%81%AC%EB%A1%A4%EB%A7%81-%EB%82%98%EB%8F%84-%ED%95%9C%EB%B2%88-%ED%95%B4%EB%B3%B4%EC%9E%90selenium%EB%B6%80%ED%84%B0-pandas%EA%B9%8C%EC%A7%80)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuI_EyHAF9z-"
      },
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.common.exceptions import TimeoutException\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from math import ceil\n",
        "from itertools import chain\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('headless') \n",
        "options.add_argument('disable-gpu') \n",
        "options.add_argument('lang=ko_KR') \n",
        "driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n",
        "\n",
        "\n",
        "def page_move(url):\n",
        "    if isinstance(url, str):\n",
        "        driver.get(url)\n",
        "    else:\n",
        "        driver.get(str(url))\n",
        "\n",
        "\n",
        "def get_chart_list():\n",
        "    try:\n",
        "        WebDriverWait(driver, 3).until(EC.presence_of_element_located((By.CLASS_NAME, 'lst50')))\n",
        "        chart_list = []\n",
        "        data = driver.find_elements_by_class_name('lst50 > td')\n",
        "        for k in data:\n",
        "            chart_list.append(k.text.split('\\n'))\n",
        "        chain_list = list(chain(*chart_list))\n",
        "        chuck_data = chunk(chain_list, 14)\n",
        "        processing_chart_list(chuck_data)\n",
        "    except TimeoutException:\n",
        "        print('해당 페이지에 차트정보가 없습니다.')\n",
        "    finally:\n",
        "        driver.quit()\n",
        "\n",
        "\n",
        "def processing_chart_list(chart_list):\n",
        "    df = pd.DataFrame(chart_list, columns=['', '순위', '증감', '', '', '제목', '가수', '앨범', '좋아요', '좋아요수', '', '', '', ''])\n",
        "    df.index = df.index + 1\n",
        "    df.to_csv(f'chart_df.csv', mode='w', encoding='utf-8-sig', header=True, index=True)\n",
        "    print(df)\n",
        "\n",
        "\n",
        "def chunk(lst, size):\n",
        "    return list(map(lambda x: lst[x * size:x * size + size], list(range(0, ceil(len(lst) / size)))))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    page_move('https://www.melon.com/chart/index.htm')\n",
        "    get_chart_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONsB9_t1HjGV"
      },
      "source": [
        "기상청 크롤링 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1sPoedZHisH"
      },
      "source": [
        "import requests\n",
        "import bs4\n",
        "\n",
        "def getRss(url):\n",
        "  resp = requests.get(url)\n",
        "  html = resp.content\n",
        "  bs = bs4.BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "  items = bs.select('data')\n",
        "\n",
        "  lst = []\n",
        "  for item in items:\n",
        "    tmef = ''\n",
        "    wf = ''\n",
        "    try:\n",
        "      tmef = item.find('tmef').get_text()\n",
        "      wf = item.find('wf').get_text()\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    dct = dict(날짜=tmef, 날씨= wf)\n",
        "    dct = [tmef, wf]\n",
        "    lst.append(dct)\n",
        "\n",
        "  return lst\n",
        "\n",
        "url = \"http://www.weather.go.kr/weather/forecast/mid-term-rss3.jsp?stnId=108\"\n",
        "lst = getRss(url)\n",
        "\n",
        "for rss in lst:\n",
        "  print(rss)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}